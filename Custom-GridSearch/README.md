The state of data mining is eager to improve as organizations of all shapes and sizes are focusing on digging deeper into organized data to secure future investments as well as the customer experience. Although, data mining is still in its infancy, organisations in a wide range of industries - including but not limited to retail, ﬁnance, heath care, manufacturing, transportation, aerospace - are already applying data mining applications and strategies to take advantage of historical data. Although the idea seems fairly simple, the entire process of recognizing patterns in data to applying mining techniques in order to produce signiﬁcant facts, relationships, trends, detection of anomaly & predictions, can be challenging from a pragmatic standpoint considering the randomness of data in real world. In this project, An application has been developed to address such challenges, while considering all possible tools & techniques that can be applied on real world data & reverse engineer the process if required to produce improvement in evaluation. This application not only implements the most commonly used pre-processing(PCA, NMF, scaling, imputation, handling imbalance), clustering(K-Means, DBSCAN, K-Mode) and classiﬁcation(KNN, Decision Tree, Deep Neural Network etc) techniques; rather it also compares between these techniques&customdevelopedversionofthesetechniques.Further, the application generates a report that compares performance metrics of all the techniques to decide the best possible solution for that data-set. This application could be really useful to generate insights from an unknown data-set without any prior knowledge about the data in few minutes.



******Before running the application, please consider these following guidelines.******
The architecture of the application is designed to obey the object oriented principles & the modular approach, which has been taken into 
consideration for future updates or easy debugging. Let's look at the architecture.....

*** The user can start from data_mining_mains file which calls the my_tools class within mining_tools file execute ML pipeline. this is one way to run the application. However data_mining_mains file produces three diffrent variations for each numerical dataset such as Raw, oversample-undersample, undersample-SMOTE; for building & evaluation of several models just like in Grid Search machine learning pipeline. The project deals with raw imbalanced data to evaluate the models first and further using mean based balanced oversampling & undersampling methodology and further undersampling & SMOTE approach to deal with imbalance in the dataset. For each of these 3 iterations several plots will be saved inside an autogenerated folder that has a meaningful name to identify the variation for example imbalance with the name of the dataset. Also within each autogenerated directory, there will be an autogenerated csv file which will contain performance metrics of over 250 models(Depending on type of data/dataset as there could be many combinations of unsupervised & supervised algorithm applicable based number of preprocessing that were applied on this project. Finally from csv file one could compare & analyze the result for selecting the optimal model for each situation in each dataset. Which means even if the dataset is imabalanced 
we can pick the optimal model for that situation without human intervention.

In this approach the number of clusters for K-Means is not Known.

**** The other approach is to run the Use-Dendrogram file which will generate a dendrogram for that dataset which can be very helpful to decide
how many clusters can work really well with the dataset as a way of feature engineering. so after that data_mining_mains script can be invoked.

*** The other approach is to run testimpute file which has a totally different architecture since it contains categorical data & missing values.
In this program, many techniques of machine learning algorithms, encoding, clustoring & imputation has been applied to work with the mushroom dataset.

In this application a generalized approach has been developed that can be applied to any unknown dataset without much prior knowledge & insights will be produced in less than 10 minutes depending on the size of the dataset(Sample output folder provided).
