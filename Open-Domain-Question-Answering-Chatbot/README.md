The quest for knowledge is deeply human, and so it is not surprising that practically as soon as there were computers we were asking them questions. Using Wikipedia articles as the knowledge source causes the task of question answering(QA) to combine the challenges of both large-scale open-domain QA and of machine comprehension of text. This paper considers the problem of answering factoid questions in an open-domain setting usingWikipediaastheuniqueknowledgesource: the answer to any factoid question is a text span in a Wikipedia article. Unlike most QA or reading comprehension models, which are best described as rerankers or extractors since they assume as input relatively small amounts of text (an article, top k sentences or passages, etc.)[2], this system integrates state of the art word embeddings viz. BERT[6], GLOVE-300[5] to not only produce ranking matrices for QA pair, but also utilizes the matrices on WikiQA[4] dataset to train our optimalmodelandÔ¨Ånallychoosethebestpossible answer based on the proprietary ranking algorithm applied here on a large corpus of several wikipedia pages. 
