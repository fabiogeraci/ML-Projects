{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test case for mushroom dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import randrange\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "class Accuracy:\n",
    "    def __init__(self,n_neighbors):\n",
    "        self.precision=[]\n",
    "        self.recall=[]\n",
    "        self.f1=[]\n",
    "        self.accuracy=[]\n",
    "        self.sensitivity=[]\n",
    "        self.specificity=[]\n",
    "        #self.identify=[]\n",
    "        #self.neighbors=[]\n",
    "        self.neighbors=n_neighbors\n",
    "    def calculate_accuracy(self,y_test,predictions,flag):\n",
    "        correct_result=0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i]==predictions[i]:\n",
    "                correct_result+=1\n",
    "        acc=correct_result/float(len(y_test))*100\n",
    "        #print(predictions)\n",
    "        conf=confusion_matrix(y_test,predictions)\n",
    "        #print(conf)\n",
    "        tn=conf[0,0]\n",
    "        tp=conf[1,1]\n",
    "        fp=conf[0,1]\n",
    "        fn=conf[1,0]\n",
    "        p=tp/(tp+fp)\n",
    "        r=tp/(tp+fn)\n",
    "        f=2*(1/(1/p + 1/r))\n",
    "        sen=tp/(fn+tp)\n",
    "        spe=fp/(fp+tn)\n",
    "        self.accuracy.append(acc)\n",
    "        self.precision.append(p)\n",
    "        self.recall.append(r)\n",
    "        self.f1.append(f)\n",
    "        self.sensitivity.append(sen)\n",
    "        self.specificity.append(spe)\n",
    "        if flag==0:\n",
    "            self.identify='KNN FROM SCRATCH'\n",
    "        else:\n",
    "            self.identify='KNN SKLEARN'\n",
    "\n",
    "\n",
    "class KNN_from_Scratch:\n",
    "\n",
    "        \n",
    "\n",
    "    def kfold_crossvalidation(self,data,kfold):\n",
    "        kfold_data=list()\n",
    "        fold_size=len(data)/kfold\n",
    "        for i in range(kfold):\n",
    "            r_fold=list()\n",
    "            while(len(r_fold)<fold_size):\n",
    "                r_fold.append(data[randrange(len(data))])\n",
    "            kfold_data.append(r_fold)\n",
    "        return kfold_data\n",
    "\n",
    "    def calculate_distance(self,p1,p2):\n",
    "        dist=0\n",
    "        for i in range(len(p1)-1):\n",
    "            dist = dist + pow((p1[i] - p2[i]),2)\n",
    "        return math.sqrt(dist) \n",
    "    def find_neighbors(self,train,test,k):\n",
    "        dist=list()\n",
    "        for train_row in train:\n",
    "            d=self.calculate_distance(test,train_row)\n",
    "            dist.append((train_row,d))\n",
    "            dist.sort(key=lambda tup: tup[1])\n",
    "        k_neighbors=list()\n",
    "        for i in range(k):\n",
    "            k_neighbors.append(dist[i][0])\n",
    "        return k_neighbors\n",
    "    def predict_labels(self,train,test,k):\n",
    "        knn=self.find_neighbors(train,test,k)\n",
    "        #print(knn)\n",
    "        knn_votes=[row[-1] for row in knn]\n",
    "        #print(knn_votes)\n",
    "        knn_pred=max(set(knn_votes), key=knn_votes.count)\n",
    "        return knn_pred\n",
    "\n",
    "data=pd.read_csv('mushrooms.csv')\n",
    "#data=data.iloc[1:,:]\n",
    "data=data.iloc[random.sample(range(1,5000),300),:]\n",
    "label_encoder = LabelEncoder()\n",
    "for i in range(data.shape[1]):\n",
    "    data.iloc[:, i] = label_encoder.fit_transform(data.iloc[:, i])\n",
    "y=data.iloc[:,-1].values.astype(np.float)\n",
    "y=y.reshape((-1,1))\n",
    "\n",
    "sc=StandardScaler()\n",
    "x_data=sc.fit_transform(data.iloc[:,:-1])\n",
    "data=np.append(x_data,y,axis=1)\n",
    "\n",
    "#print(k_data)\n",
    "accuracy=list()\n",
    "precision=list()\n",
    "recall=list()\n",
    "f1=list()\n",
    "sensitivity=list()\n",
    "specificity=list()\n",
    "identify=list()\n",
    "neighbors=list()\n",
    "processing_time=list()\n",
    "\n",
    "number_of_neighbors=list(range(1,51))\n",
    "for n in range(len(number_of_neighbors)):\n",
    "    processing_time_sklearn=list()\n",
    "    processing_time_scratch=list()\n",
    "    ob=KNN_from_Scratch()\n",
    "    ob1=Accuracy(number_of_neighbors[n])\n",
    "    sklearnob=Accuracy(number_of_neighbors[n])\n",
    "    k_data=ob.kfold_crossvalidation(data,5)\n",
    "    for fold in k_data:\n",
    "        i=0\n",
    "        trainset=list(k_data)\n",
    "        trainset.pop(i)\n",
    "        trainset=sum(trainset,[])\n",
    "        trainset=np.array(trainset)\n",
    "        testset=list(fold)\n",
    "        testset=np.array(testset)\n",
    "        x_train=np.array(trainset[:,:-1])\n",
    "        y_train=np.array(trainset[:,-1])\n",
    "        x_test=np.array(testset[:,:-1])\n",
    "        y_test=np.array(testset[:,-1])\n",
    "        #print(y_train)\n",
    "\n",
    "        predictions=list()\n",
    "        #print(np.array(x_test).shape)\n",
    "        y_test=np.array(y_test).reshape((-1,1))\n",
    "        sklearn_start=time.clock()\n",
    "        clf=KNeighborsClassifier(n_neighbors=number_of_neighbors[n])\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred=clf.predict(x_test)\n",
    "        #print('y_pred',y_pred)\n",
    "        sklearn_final=time.clock()\n",
    "        processing_time_sklearn.append(sklearn_final-sklearn_start)\n",
    "        #sklearn_accuracy.append(accuracy_score(y_test,y_pred))\n",
    "        sklearnob.calculate_accuracy(y_test,y_pred,1)\n",
    "        #print(np.array(y_test).shape)\n",
    "        data_test=np.append(x_test,y_test,axis=1)\n",
    "        y_train=np.array(y_train).reshape((-1,1))\n",
    "        data_train=np.append(x_train,y_train,axis=1)\n",
    "        knn_scratch_start=time.clock()\n",
    "        for test in data_test:\n",
    "            pred=ob.predict_labels(data_train,test,number_of_neighbors[i])\n",
    "            predictions.append(pred)\n",
    "        #print('Accuracy Score',accuracy_score(y_test,predictions))\n",
    "        knn_scratch_final=time.clock()\n",
    "\n",
    "        processing_time_scratch.append(knn_scratch_final-knn_scratch_start)\n",
    "        ob1.calculate_accuracy(y_test,predictions,0)\n",
    "    #print('Average Accuracy KNN from Scratch ',sum(ob1.accuracy)/len(ob1.accuracy))\n",
    "    #print('Average Precision KNN from Scratch ',sum(ob1.precision)/len(ob1.precision))\n",
    "    #print('Average Recall KNN from Scratch ',sum(ob1.recall)/len(ob1.recall))\n",
    "    #print('Average F1 KNN from Scratch ',sum(ob1.f1)/len(ob1.f1))\n",
    "    #print('Average Accuracy for KNN Sklearn',sum(sklearn_accuracy)/len(sklearn_accuracy))\n",
    "    accuracy.append(sum(ob1.accuracy)/len(ob1.accuracy))\n",
    "    accuracy.append(sum(sklearnob.accuracy)/len(sklearnob.accuracy))\n",
    "    identify.append(ob1.identify)\n",
    "    identify.append(sklearnob.identify)\n",
    "    neighbors.append(ob1.neighbors)\n",
    "    neighbors.append(sklearnob.neighbors)\n",
    "    precision.append(sum(ob1.precision)/len(ob1.precision))\n",
    "    precision.append(sum(sklearnob.precision)/len(sklearnob.precision))\n",
    "    recall.append(sum(ob1.recall)/len(ob1.recall))\n",
    "    recall.append(sum(sklearnob.recall)/len(sklearnob.recall))\n",
    "    f1.append(sum(ob1.f1)/len(ob1.f1))\n",
    "    f1.append(sum(sklearnob.f1)/len(sklearnob.f1))\n",
    "    sensitivity.append(sum(ob1.sensitivity)/len(ob1.sensitivity))\n",
    "    sensitivity.append(sum(sklearnob.sensitivity)/len(sklearnob.sensitivity))\n",
    "    specificity.append(sum(ob1.specificity)/len(ob1.specificity))\n",
    "    specificity.append(sum(sklearnob.specificity)/len(sklearnob.specificity))\n",
    "    processing_time.append(sum(processing_time_scratch)/len(processing_time_scratch))\n",
    "    processing_time.append(sum(processing_time_sklearn)/len(processing_time_sklearn))\n",
    "    \n",
    "#print()\n",
    "#print(accuracy)\n",
    "list_for_export=[identify,neighbors,precision,recall,f1,sensitivity,specificity,processing_time,accuracy]\n",
    "list_for_export=np.array(list_for_export).transpose()\n",
    "#print(list_for_export)\n",
    "export_data=pd.DataFrame(data=list_for_export[0:,0:],columns=['Identifier','Number of Neighbors','Precision','Recall','F1 Score','Sensitivity','Specificity','Processing Time','Accuracy'])\n",
    "export_data.to_csv('KNN_Export.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this test case is knn_export_dataset.csv, which is provided in the zip file. This test case is used as there were categorical data present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test case of KNN on breast-cancer dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import randrange\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "#This class is designed to calculate accuracy,precision,recall & all the other performance metrics for both algorithms\n",
    "class Accuracy:\n",
    "    def __init__(self,n_neighbors):\n",
    "        self.precision=[]\n",
    "        self.recall=[]\n",
    "        self.f1=[]\n",
    "        self.accuracy=[]\n",
    "        self.sensitivity=[]\n",
    "        self.specificity=[]\n",
    "        #self.identify=[]\n",
    "        #self.neighbors=[]\n",
    "        self.neighbors=n_neighbors\n",
    "    def calculate_accuracy(self,y_test,predictions,flag):\n",
    "        correct_result=0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i]==predictions[i]:\n",
    "                correct_result+=1\n",
    "        acc=correct_result/float(len(y_test))*100\n",
    "        #print(predictions)\n",
    "        conf=confusion_matrix(y_test,predictions)\n",
    "        #print(conf)\n",
    "        tn=conf[0,0]\n",
    "        tp=conf[1,1]\n",
    "        fp=conf[0,1]\n",
    "        fn=conf[1,0]\n",
    "        p=tp/(tp+fp)\n",
    "        r=tp/(tp+fn)\n",
    "        f=2*(1/(1/p + 1/r))\n",
    "        sen=tp/(fn+tp)\n",
    "        spe=fp/(fp+tn)\n",
    "        self.accuracy.append(acc)\n",
    "        self.precision.append(p)\n",
    "        self.recall.append(r)\n",
    "        self.f1.append(f)\n",
    "        self.sensitivity.append(sen)\n",
    "        self.specificity.append(spe)\n",
    "        if flag==0:\n",
    "            self.identify='KNN FROM SCRATCH'\n",
    "        else:\n",
    "            self.identify='KNN SKLEARN'\n",
    "\n",
    "\n",
    "class KNN_from_Scratch:\n",
    "\n",
    "        \n",
    "\n",
    "    def kfold_crossvalidation(self,data,kfold): #Mathod for k fold cross validation, here this program is using 5 fold\n",
    "        kfold_data=list()\n",
    "        fold_size=len(data)/kfold #fold size self explanatory\n",
    "        for i in range(kfold):\n",
    "            r_fold=list()\n",
    "            while(len(r_fold)<fold_size): #randomly choosing the rows till it reaches the fold size\n",
    "                r_fold.append(data[randrange(len(data))])\n",
    "            kfold_data.append(r_fold)\n",
    "        return kfold_data\n",
    "\n",
    "    def calculate_distance(self,p1,p2): #calculating euclidean distance\n",
    "        dist=0\n",
    "        for i in range(len(p1)-1):\n",
    "            dist = dist + pow((p1[i] - p2[i]),2)\n",
    "        return math.sqrt(dist) \n",
    "    def find_neighbors(self,train,test,k):\n",
    "        dist=list()\n",
    "        for train_row in train: #for each training row it is calculating distance between train & for the parameterised test row\n",
    "            d=self.calculate_distance(test,train_row)\n",
    "            dist.append((train_row,d))\n",
    "            dist.sort(key=lambda tup: tup[1]) #making a tuple of train row & it's distance\n",
    "        k_neighbors=list()\n",
    "        for i in range(k):\n",
    "            k_neighbors.append(dist[i][0]) #selecting only nearest neighbors based on k value i.e only the row not the distance\n",
    "        return k_neighbors\n",
    "    def predict_labels(self,train,test,k):\n",
    "        knn=self.find_neighbors(train,test,k)\n",
    "        #print(knn)\n",
    "        knn_votes=[row[-1] for row in knn] #labels of all nearest neighbors\n",
    "        #print(knn_votes)\n",
    "        knn_pred=max(set(knn_votes), key=knn_votes.count) #maximum number of votes or most neighbors that have same label\n",
    "        return knn_pred\n",
    "\n",
    "data=pd.read_csv('breast-cancer.data')\n",
    "data=data.iloc[1:,:]\n",
    "data=data.iloc[random.sample(range(1,650),300),:] #choosing 300 rows randomly otherwise it's taking a looooong time to execute\n",
    "\n",
    "y=data.iloc[:,-1].values.astype(np.float)\n",
    "y=y.reshape((-1,1)) #1d to 2d array this is required for np.append\n",
    "\n",
    "sc=StandardScaler() #scaling the data\n",
    "x_data=sc.fit_transform(data.iloc[:,:-1])\n",
    "data=np.append(x_data,y,axis=1)\n",
    "\n",
    "#print(k_data)\n",
    "accuracy=list()\n",
    "precision=list()\n",
    "recall=list()\n",
    "f1=list()\n",
    "sensitivity=list()\n",
    "specificity=list()\n",
    "identify=list()\n",
    "neighbors=list()\n",
    "processing_time=list()\n",
    "#The program is checking performance metric for both algorithms starting from 1 to 50\n",
    "number_of_neighbors=list(range(1,51))\n",
    "for n in range(len(number_of_neighbors)):\n",
    "    processing_time_sklearn=list()\n",
    "    processing_time_scratch=list()\n",
    "    ob=KNN_from_Scratch() #calling the object\n",
    "    ob1=Accuracy(number_of_neighbors[n]) \n",
    "    sklearnob=Accuracy(number_of_neighbors[n])\n",
    "    k_data=ob.kfold_crossvalidation(data,5) #ob is just the object of KNN from scratch but it executes the cross validation method which \n",
    "    for fold in k_data: #is used for both sklearn & scratch class as both the class must get the same data for each validation\n",
    "        i=0\n",
    "        trainset=list(k_data) #creating training & testset from the folds\n",
    "        trainset.pop(i)\n",
    "        trainset=sum(trainset,[])\n",
    "        trainset=np.array(trainset)\n",
    "        testset=list(fold)\n",
    "        testset=np.array(testset)\n",
    "        x_train=np.array(trainset[:,:-1])\n",
    "        y_train=np.array(trainset[:,-1])\n",
    "        x_test=np.array(testset[:,:-1])\n",
    "        y_test=np.array(testset[:,-1])\n",
    "        #print(y_train)\n",
    "\n",
    "        predictions=list()\n",
    "        #print(np.array(x_test).shape)\n",
    "        y_test=np.array(y_test).reshape((-1,1)) #1d to 2d array this was used as the class KNN from scratch designed earlier\n",
    "        sklearn_start=time.clock()\n",
    "        clf=KNeighborsClassifier(n_neighbors=number_of_neighbors[n])\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred=clf.predict(x_test) \n",
    "        #print('y_pred',y_pred)\n",
    "        sklearn_final=time.clock()\n",
    "        processing_time_sklearn.append(sklearn_final-sklearn_start) #calculating the processing time\n",
    "        #sklearn_accuracy.append(accuracy_score(y_test,y_pred))\n",
    "        sklearnob.calculate_accuracy(y_test,y_pred,1) #same accuracy class is used for evaluation metric\n",
    "        #print(np.array(y_test).shape)\n",
    "        data_test=np.append(x_test,y_test,axis=1)\n",
    "        y_train=np.array(y_train).reshape((-1,1))\n",
    "        data_train=np.append(x_train,y_train,axis=1)\n",
    "        knn_scratch_start=time.clock()\n",
    "        for test in data_test:\n",
    "            pred=ob.predict_labels(data_train,test,number_of_neighbors[i])\n",
    "            predictions.append(pred)\n",
    "        #print('Accuracy Score',accuracy_score(y_test,predictions))\n",
    "        knn_scratch_final=time.clock()\n",
    "\n",
    "        processing_time_scratch.append(knn_scratch_final-knn_scratch_start) #calculating time\n",
    "        ob1.calculate_accuracy(y_test,predictions,0)\n",
    "    accuracy.append(sum(ob1.accuracy)/len(ob1.accuracy)) #adding the average scores into the list for all k numnber of folds\n",
    "    accuracy.append(sum(sklearnob.accuracy)/len(sklearnob.accuracy))\n",
    "    identify.append(ob1.identify)\n",
    "    identify.append(sklearnob.identify)\n",
    "    neighbors.append(ob1.neighbors)\n",
    "    neighbors.append(sklearnob.neighbors)\n",
    "    precision.append(sum(ob1.precision)/len(ob1.precision))\n",
    "    precision.append(sum(sklearnob.precision)/len(sklearnob.precision))\n",
    "    recall.append(sum(ob1.recall)/len(ob1.recall))\n",
    "    recall.append(sum(sklearnob.recall)/len(sklearnob.recall))\n",
    "    f1.append(sum(ob1.f1)/len(ob1.f1))\n",
    "    f1.append(sum(sklearnob.f1)/len(sklearnob.f1))\n",
    "    sensitivity.append(sum(ob1.sensitivity)/len(ob1.sensitivity))\n",
    "    sensitivity.append(sum(sklearnob.sensitivity)/len(sklearnob.sensitivity))\n",
    "    specificity.append(sum(ob1.specificity)/len(ob1.specificity))\n",
    "    specificity.append(sum(sklearnob.specificity)/len(sklearnob.specificity))\n",
    "    processing_time.append(sum(processing_time_scratch)/len(processing_time_scratch))\n",
    "    processing_time.append(sum(processing_time_sklearn)/len(processing_time_sklearn))\n",
    "    \n",
    "#print()\n",
    "#print(accuracy)\n",
    "list_for_export=[identify,neighbors,precision,recall,f1,sensitivity,specificity,processing_time,accuracy] #making the entire list\n",
    "list_for_export=np.array(list_for_export).transpose()\n",
    "#print(list_for_export)\n",
    "export_data=pd.DataFrame(data=list_for_export[0:,0:],columns=['Identifier','Number of Neighbors','Precision','Recall','F1 Score','Sensitivity','Specificity','Processing Time','Accuracy'])\n",
    "export_data.to_csv('KNN_Export.csv') #exporting into csv file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The output of this test case is knn_export_dataset.csv, which is provided in the zip file. This dataset is used as it only contains numerical data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
