Data mining although still in its infancy, organisations in a wide range of industries - including but not limited to retail, ﬁnance, heath care, manufacturing, transportation, aerospace - are already applying data mining applications and machine learning algorithms to take advantage of historical data.KnearestNeighborsisoneofthemostpopularalgorithms which has a high efﬁcacy & intuitive by nature in terms of implementation. In this project, K Nearest Neighbors algorithm has been implemented from scratch in python & analysed in comparison with in built KNN of Sklearn library. The performance metrics of both the algorithms have been compared for unique values of parameter k, which in turn is analysed further in R with line plots & hypothesis testing. The idea is to analyse if the algorithm from scratch performs better in comparison with Sklearn’s KNN for a given dataset on several test cases. 

The KNN algorithm is a robust classiﬁer which is often used as a benchmark for more complex classiﬁers such as Artiﬁcial Neural Network or Support vector machine. It is a non-parametric algorithm which means there are no assumptions to be met compared to algorithms like linear regression which has lots of assumptions. It has the ﬂexibility for the user to choose from any of the distance based approach for the modelling,

• Euclidean Distance
• Hamming Distance
• Manhattan Distance
• Minkowski Distance

In this project, Euclidean distance has been applied for modelling with KNN algorithm. The data-set is scaled & encoded before applying KNN algorithm. Also cross-validation technique has been implemented in this project to increase the robustness of the algorithm, as all the performance metrics has been determined as the average of those metrics for all k folds where k is the number of folds in crossvalidation. The computational time although a little higher compared to the Sklearn counterpart, the KNN algorithm from scratch produces a much robust performance & very consistent results when compared with Sklearn’s algorithm. 
